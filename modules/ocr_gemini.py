# modules/ocr_gemini.py
# åŠŸèƒ½ï¼š
# 1. è‹¥ data/{file_name}.pdf ä¸å­˜åœ¨ â†’ å°‡ data/{file_name}/*.png åˆä½µæˆ PDF
# 2. å°‡ PDF åˆ‡å‰²æˆå¤šå€‹ chunkï¼ˆé è¨­æ¯ 100 é ï¼‰
# 3. å‘¼å« Gemini é€å¡Š OCR
# 4. å›å‚³ dict: {"subtitle0001": "æ–‡å­—", ...}
# âš ï¸ ä¸è‡ªå‹•å¯«å…¥ JSONï¼Œç”±å¤–å±¤ä¸»ç¨‹å¼æ±ºå®š

from __future__ import annotations
import os, re, json, math, time, glob
from pathlib import Path
from typing import Dict, List, Optional
from pypdf import PdfReader, PdfWriter
from PIL import Image
import google.generativeai as genai
from google.api_core import exceptions as google_exceptions
import config


# --------- åœ–ç‰‡åˆä½µæˆ PDF ---------
def _images_to_pdf(file_name: str) -> Path:
    pdf_path = Path("data") / f"{file_name}.pdf"
    if pdf_path.exists():
        return pdf_path

    folder = Path("data") / file_name
    image_files = sorted(glob.glob(str(folder / "*.png")))
    if not image_files:
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°ä»»ä½•åœ–ç‰‡ï¼š{folder}/*.png")

    os.makedirs(pdf_path.parent, exist_ok=True)
    imgs = [Image.open(p).convert("RGB") for p in image_files]
    try:
        first, rest = imgs[0], imgs[1:]
        first.save(pdf_path, save_all=True, append_images=rest)
    finally:
        for im in imgs:
            im.close()

    print(f"âœ… å·²åˆä½µ {len(image_files)} å¼µåœ–ç‰‡ç‚º PDFï¼š{pdf_path}")
    return pdf_path


# --------- PDF æ‹†å¡Š ---------
def _split_pdf_into_chunks(pdf_path: Path, chunk_size: int = 100) -> List[Path]:
    reader = PdfReader(str(pdf_path))
    total_pages = len(reader.pages)
    if total_pages == 0:
        raise ValueError("PDF æ²’æœ‰é é¢")

    out: List[Path] = []
    base = pdf_path.with_suffix("")
    for i in range(0, total_pages, chunk_size):
        writer = PdfWriter()
        for j in range(i, min(i + chunk_size, total_pages)):
            writer.add_page(reader.pages[j])
        chunk_file = Path(f"{base}_chunk_{len(out)+1}.pdf")
        with open(chunk_file, "wb") as f:
            writer.write(f)
        out.append(chunk_file)
    return out


# --------- å–®ä¸€ Gemini OCR ---------
def _gemini_ocr_one(pdf_path: Path, api_key: str, timeout_sec: int = 600) -> str:
    genai.configure(api_key=api_key)
    remote = genai.upload_file(path=str(pdf_path))
    try:
        model = genai.GenerativeModel(
            model_name="gemini-flash-latest",
            generation_config={"temperature": 0.1},
            safety_settings=[
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
            ],
        )

        prompt = (
            "é€™æ˜¯ä¸€ä»½ç”±åœ–ç‰‡çµ„æˆçš„ PDFã€‚è«‹é€é æ“·å–æ‰€æœ‰ç¹é«”ä¸­æ–‡èˆ‡è‹±æ–‡æ–‡å­—ã€‚\n"
            "æ¯é é–‹é ­å‹™å¿…ä»¥ã€ç¬¬Xé ã€ç¨ç«‹ä¸€è¡Œè¡¨ç¤ºé ç¢¼ã€‚\n"
            "è¼¸å‡ºç¯„ä¾‹ï¼š\nç¬¬1é \n<å…§å®¹>\nç¬¬2é \n<å…§å®¹>\n"
        )

        resp = model.generate_content([prompt, remote], request_options={"timeout": timeout_sec})
        return (resp.text or "").strip()
    finally:
        try:
            genai.delete_file(remote.name)
        except Exception:
            pass


# --------- åˆ†é æ–‡å­—è§£æ ---------
_PAGE_SPLIT = re.compile(r"(?:^|\n)ç¬¬\s*([0-9ï¼-ï¼™]+)\s*é (?:[ï¼š:\-\s]*)(?!\S)", re.IGNORECASE)

def _parse_pages_to_dict(full_text: str) -> Dict[int, str]:
    if not full_text.strip():
        return {}
    parts = _PAGE_SPLIT.split(full_text)
    out: Dict[int, str] = {}
    if len(parts) > 1:
        for i in range(1, len(parts), 2):
            page_no_raw = parts[i]
            page_text = parts[i + 1] if i + 1 < len(parts) else ""
            trans = str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™", "0123456789")
            page_no = int(page_no_raw.translate(trans))
            out[page_no] = page_text.strip()
        return out

    # è‹¥æ¨¡å‹æ²’åˆ†é  â†’ ç”¨ç©ºè¡Œåˆ‡æ®µ
    paras = [p for p in re.split(r"\n{2,}", full_text) if p.strip()]
    for idx, txt in enumerate(paras, 1):
        out[idx] = txt.strip()
    return out


# --------- ä¸»å‡½å¼ï¼ˆçµ¦ä¸»ç¨‹å¼å‘¼å«ï¼‰ ---------
def run(
    file_name: str,
    *,
    chunk_size: int = 100,
    max_retries: int = 3,
    sleep_on_rate_limit: int = 40,
    timeout_sec: int = 600,
    api_key: Optional[str] = None,
) -> Dict[str, str]:
    """
    åŸ·è¡Œæµç¨‹ï¼š
      1) è‹¥ data/{file_name}.pdf ä¸å­˜åœ¨ï¼Œå¾ data/{file_name}/*.png å»ºç«‹
      2) åˆ‡å¡Š OCR
      3) å›å‚³å­—å…¸ {"subtitle0001": "å…§å®¹", ...}
    """
    pdf_path = _images_to_pdf(file_name)

    if not api_key:
        cfg = config.load_config()
        api_key = cfg.get("api_key") or cfg.get("API_key") or ""
    if not api_key:
        raise ValueError("ç¼ºå°‘ API Key")

    chunk_files = _split_pdf_into_chunks(pdf_path, chunk_size=chunk_size)

    image_texts_by_page: Dict[int, str] = {}
    try:
        for chunk in chunk_files:
            text = None
            for attempt in range(1, max_retries + 1):
                try:
                    text = _gemini_ocr_one(chunk, api_key=api_key, timeout_sec=timeout_sec)
                    break
                except (google_exceptions.ResourceExhausted, google_exceptions.ServiceUnavailable):
                    if attempt == max_retries:
                        raise
                    time.sleep(sleep_on_rate_limit)
                except Exception:
                    if attempt == max_retries:
                        raise
                    time.sleep(2)

            if not text:
                continue

            local = _parse_pages_to_dict(text)
            base = len(image_texts_by_page)
            for k in sorted(local.keys()):
                image_texts_by_page[base + k] = local[k].strip()
    finally:
        for f in chunk_files:
            try: os.remove(f)
            except Exception: pass

    # è½‰æˆ subtitle_0001 å½¢å¼
    # æŠŠåŸæœ¬çš„ key ç”Ÿæˆè™•æ”¹æˆæœ‰åº•ç·šå½¢å¼
    image_texts = {f"subtitle_{i:04d}.png": image_texts_by_page[p]
        for i, p in enumerate(sorted(image_texts_by_page.keys()), 1)}


    print(f"ğŸ“˜ OCR å®Œæˆï¼š{file_name}ï¼ˆå…± {len(image_texts)} é ï¼‰")
    return image_texts


# if __name__ == "__main__":
#     # æ¸¬è©¦ï¼šæœƒå›å‚³å­—å…¸ä½†ä¸å­˜æª”
#     d = run("å†è¦‹æŸæ—ä¸­æ–‡")
#     print(d)
